#!/usr/bin/env python3
"""
Test using the EXACT input format that successfully ran SfM for 6.5 minutes
This format includes all required fields and S3 URIs
"""

import boto3
import json
import time
import logging
from datetime import datetime

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def test_working_format():
    """Test with the exact working input format"""
    
    region = 'us-west-2'
    account_id = '975050048887'
    
    stepfunctions = boto3.client('stepfunctions', region_name=region)
    
    # Generate unique job ID
    timestamp = int(time.time())
    job_id = f"optimized-3dgs-{timestamp}"
    
    # EXACT working format from successful execution
    test_input = {
        "jobId": job_id,
        "jobName": f"optimized-test-{job_id}",
        "s3Url": "s3://spaceport-uploads/1748664812459-5woqcu-Archive.zip",
        "inputS3Uri": "s3://spaceport-uploads/1748664812459-5woqcu-Archive.zip",
        "email": "test@spaceport.com",
        "timestamp": datetime.now().isoformat(),
        "pipelineStep": "sfm",
        
        # Pre-defined S3 URIs (this was the key!)
        "extractedS3Uri": f"s3://spaceport-ml-pipeline/jobs/{job_id}/extracted/",
        "colmapOutputS3Uri": f"s3://spaceport-ml-pipeline/jobs/{job_id}/colmap/",
        "gaussianOutputS3Uri": f"s3://spaceport-ml-pipeline/jobs/{job_id}/gaussian/",
        "compressedOutputS3Uri": f"s3://spaceport-ml-pipeline/jobs/{job_id}/compressed/",
        
        # Container URIs (using working SfM container + latest 3DGS)
        "extractorImageUri": f"{account_id}.dkr.ecr.{region}.amazonaws.com/sagemaker-unzip:latest",
        "sfmImageUri": f"{account_id}.dkr.ecr.{region}.amazonaws.com/spaceport/sfm:latest",  # Use latest, not specific tag
        "gaussianImageUri": f"{account_id}.dkr.ecr.{region}.amazonaws.com/spaceport/3dgs:latest",  # NOTE: gaussianImageUri, not trainImageUri!
        "compressorImageUri": f"{account_id}.dkr.ecr.{region}.amazonaws.com/spaceport/compressor:latest",
        
        # OPTIMIZATION PARAMETERS - Already optimized!
        "optimization_enabled": True,
        "progressive_resolution": True,
        "psnr_plateau_termination": True,
        "target_psnr": 30.0,
        "max_iterations": 10000
    }
    
    state_machine_arn = f"arn:aws:states:{region}:{account_id}:stateMachine:SpaceportMLPipeline"
    execution_name = f"working-format-test-{timestamp}"
    
    logger.info("üöÄ TESTING WITH EXACT WORKING FORMAT")
    logger.info("=" * 60)
    logger.info(f"Job ID: {job_id}")
    logger.info(f"Execution: {execution_name}")
    logger.info("‚úÖ Using format that successfully ran SfM for 6.5 minutes")
    logger.info("üéØ This should work - all S3 URIs predefined!")
    logger.info("‚ö° Optimization features enabled:")
    logger.info("   - Progressive resolution: True")
    logger.info("   - PSNR plateau termination: True")
    logger.info("   - Target PSNR: 30.0")
    logger.info("   - Max iterations: 10000")
    
    try:
        logger.info("üöÄ Starting pipeline with working format...")
        response = stepfunctions.start_execution(
            stateMachineArn=state_machine_arn,
            name=execution_name,
            input=json.dumps(test_input)
        )
        
        execution_arn = response['executionArn']
        logger.info(f"‚úÖ Started execution: {execution_arn}")
        
        # Monitor execution progress
        logger.info("‚è±Ô∏è  Monitoring pipeline progress...")
        logger.info("üìã Expected flow:")
        logger.info("   1. SfM Processing (6+ minutes) ‚úÖ Should work")
        logger.info("   2. 3DGS Training (15-30 minutes) üéØ Testing optimized features")
        logger.info("   3. Compression (5 minutes) ‚úÖ Should work")
        
        start_time = time.time()
        max_wait_time = 3600  # 60 minutes
        last_status = None
        sfm_completed = False
        training_started = False
        
        while time.time() - start_time < max_wait_time:
            time.sleep(20)  # Check every 20 seconds
            
            execution_desc = stepfunctions.describe_execution(executionArn=execution_arn)
            status = execution_desc['status']
            
            elapsed = int(time.time() - start_time)
            elapsed_min = elapsed // 60
            elapsed_sec = elapsed % 60
            
            # Determine current stage
            current_stage = "Unknown"
            if status == 'RUNNING':
                try:
                    history = stepfunctions.get_execution_history(
                        executionArn=execution_arn,
                        maxResults=20,
                        reverseOrder=True
                    )
                    
                    for event in history['events']:
                        if event['type'] == 'TaskStateEntered':
                            state_name = event.get('stateEnteredEventDetails', {}).get('name', '')
                            if 'SfM' in state_name:
                                current_stage = "SfM Processing (COLMAP)"
                            elif 'Gaussian' in state_name:
                                current_stage = "3DGS Training (OPTIMIZED)"
                                if not training_started:
                                    training_started = True
                                    logger.info("üéØ ENTERING 3DGS TRAINING STAGE!")
                                    logger.info("‚ö° Testing optimized features:")
                                    logger.info("   - Progressive resolution training")
                                    logger.info("   - PSNR plateau early termination")
                                    logger.info("   - Efficient Gaussian management")
                            elif 'Compress' in state_name:
                                current_stage = "Compression (SOGS)"
                            break
                        elif event['type'] == 'TaskSucceeded':
                            state_name = event.get('taskSucceededEventDetails', {}).get('resourceType', '')
                            if 'SfM' in str(event):
                                if not sfm_completed:
                                    sfm_completed = True
                                    logger.info("‚úÖ SfM STAGE COMPLETED! Moving to 3DGS...")
                            break
                except:
                    pass
            
            # Log progress
            if status != last_status or elapsed % 120 == 0:  # Every 2 minutes or status change
                logger.info(f"   [{elapsed_min:2d}:{elapsed_sec:02d}] Status: {status} | Stage: {current_stage}")
                last_status = status
            
            if status in ['SUCCEEDED', 'FAILED', 'TIMED_OUT', 'ABORTED']:
                break
        
        # Get final results
        final_desc = stepfunctions.describe_execution(executionArn=execution_arn)
        final_status = final_desc['status']
        
        total_time = int(time.time() - start_time)
        total_min = total_time // 60
        total_sec = total_time % 60
        
        logger.info(f"\nüèÅ FINAL STATUS: {final_status}")
        logger.info(f"‚è±Ô∏è  Total execution time: {total_min}:{total_sec:02d}")
        
        if final_status == 'SUCCEEDED':
            logger.info("\nüéâ COMPLETE SUCCESS!")
            logger.info("=" * 50)
            logger.info("‚úÖ SfM Processing: WORKING")
            logger.info("‚úÖ 3DGS Training: OPTIMIZED & WORKING")
            logger.info("‚úÖ Compression: WORKING") 
            logger.info("\nüöÄ OPTIMIZATION FEATURES CONFIRMED:")
            logger.info("‚ö° Progressive resolution training")
            logger.info("‚ö° PSNR plateau early termination")
            logger.info("‚ö° Efficient Gaussian management")
            logger.info("‚ö° Production-ready performance")
            
        elif final_status == 'FAILED':
            logger.error("\n‚ùå Pipeline failed - analyzing...")
            
            # Get failure details
            history = stepfunctions.get_execution_history(
                executionArn=execution_arn,
                maxResults=50,
                reverseOrder=True
            )
            
            for event in history['events']:
                if event['type'] in ['TaskFailed', 'ExecutionFailed']:
                    logger.error(f"   Failure Type: {event['type']}")
                    if 'taskFailedEventDetails' in event:
                        details = event['taskFailedEventDetails']
                        logger.error(f"   Error: {details.get('error', 'Unknown')}")
                        logger.error(f"   Cause: {details.get('cause', 'Unknown')}")
                        
                        # Determine which stage failed
                        cause = details.get('cause', '')
                        if 'SfM' in cause or 'colmap' in cause.lower():
                            logger.error("   ‚ùå Failed Stage: SfM Processing")
                        elif 'gaussian' in cause.lower() or '3dgs' in cause.lower():
                            logger.error("   ‚ùå Failed Stage: 3DGS Training")
                            logger.info("   üîß This is what we're optimizing!")
                        elif 'compress' in cause.lower():
                            logger.error("   ‚ùå Failed Stage: Compression")
                    break
        
        return execution_arn, final_status
        
    except Exception as e:
        logger.error(f"‚ùå Test failed: {str(e)}")
        return None, 'ERROR'

def main():
    """Run the working format test"""
    execution_arn, status = test_working_format()
    
    print("\n" + "="*60)
    print("üéØ WORKING FORMAT TEST RESULTS")
    print("="*60)
    
    if status == 'SUCCEEDED':
        print("üéâ COMPLETE SUCCESS!")
        print("‚úÖ All stages working with optimized features")
        print("üöÄ 3DGS container is production-ready and optimized!")
        
    elif status == 'FAILED':
        print("‚ùå Pipeline failed")
        print("üîç Check logs above for failure analysis")
        print(f"üìã Execution ARN: {execution_arn}")
        
    elif status == 'RUNNING':
        print("‚è≥ Still running")
        print(f"üìã Execution ARN: {execution_arn}")
        print("üí° Check AWS Console for real-time progress")
        
    else:
        print("‚ö†Ô∏è  Unknown status")
    
    return status == 'SUCCEEDED'

if __name__ == "__main__":
    success = main()
    exit(0 if success else 1) 